{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ijU_u6uj3Sio"
   },
   "source": [
    "# SIGNAL-seq ADT mapping with kallisto KITE workflow\n",
    "\n",
    "1) Map the FASTQ data to barcode reference using the Kallisto KITE pipeline\n",
    "2) Collapse the polyA and randomHex barcodes into CBs\n",
    "3) write out the data to a .h5ad file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ptOROSxBx8n"
   },
   "source": [
    "## Env Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yxWdqYJapNHm"
   },
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "from scipy import sparse, io\n",
    "import sys, os, argparse\n",
    "\n",
    "# Import utils\n",
    "# Get the current working directory\n",
    "current_dir = os.getcwd()\n",
    "utils_path = os.path.join(current_dir, '../../', 'utils')\n",
    "sys.path.append(utils_path)\n",
    "\n",
    "# Import adt utils functions\n",
    "from adt_utils import merge_rt_barcodes, pairwise_rt_comparison \n",
    "\n",
    "matplotlib.rcParams.update({'font.size': 12})\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DioH-jvT5sKn"
   },
   "source": [
    "## Data input\n",
    "\n",
    "1) PE FASTQ format input files \n",
    "2) ADT antibody panel with barcodes and metadata required to generate mapping index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AyMZpldO3e7X"
   },
   "outputs": [],
   "source": [
    "# Load features reference  \n",
    "# Clean up the antibody names for problematic characters\n",
    "df = pd.read_csv('barcode_layouts/Ex0015_kite_panel.csv')\n",
    "df['Antigen']=df['Antigen'].str.replace(' ','_')\n",
    "df['Antigen']=df['Antigen'].str.replace('(','')\n",
    "df['Antigen']=df['Antigen'].str.replace(')','')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the tsv raw feature file to input into Kallisto - KITE\n",
    "df[['Barcode', 'Antigen']].to_csv('barcode_layouts/features.tsv', index=None, header=None, sep='\\t')\n",
    "!cat barcode_layouts/features.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use kb to generate the mismatch kallisto index.\n",
    "!kb ref -i barcode_layouts/mismatch.idx -f1 barcode_layouts/mismatch.fa -g barcode_layouts/t2g.txt --workflow kite barcode_layouts/features.tsv --overwrite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8vawR3Yo4GoP"
   },
   "source": [
    "## Run kallisto and bustools to feature count matrix in H5AD format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NqO22xH84BUM"
   },
   "outputs": [],
   "source": [
    "# Run kb count pipeline\n",
    "#%%time\n",
    "!kb count --h5ad -i barcode_layouts/mismatch.idx -o split_adt/ -w barcode_layouts/split_seqv2_barcode_wlist.txt -g barcode_layouts/t2g.txt -x 1,10,18,1,48,56,1,78,86:1,0,10:0,0,0 --workflow kite -t 2 --keep-tmp --overwrite\\\n",
    "~/PATH/ex0015_adt_80_L001_S5_R1_001.fastq.gz ~/PATH/ex0015_adt_80_L001_S5_R2_001.fastq.gz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mpn9X0hqBjYA"
   },
   "outputs": [],
   "source": [
    "# Use bustools to capture the reads based on umi, ADT_barcode or split_barcode.\n",
    "# Can filter based on whitelist here too, if needed in the future\n",
    "!bustools text -o split_adt/bus_text_raw.txt split_adt/output.bus \n",
    "!bustools text -o split_adt/bus_text_pp.txt split_adt/output.unfiltered.bus "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sZmv_OiIqEdw"
   },
   "source": [
    "## Generate anndata object for preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ktUFMcJ1qdj0"
   },
   "outputs": [],
   "source": [
    "# Figure output directory\n",
    "sc.settings.figdir = 'pre_processing_figures'\n",
    "\n",
    "#  kallisto adt x barocde data\n",
    "adata = sc.read_h5ad('split_adt/counts_unfiltered/adata.h5ad')\n",
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate QC counts for CBs\n",
    "sc.pp.calculate_qc_metrics(adata, percent_top=None, log1p=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VYlMjOCU-hKI"
   },
   "source": [
    "## Collapse RT and Random Hex barcodes (BC 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yI0mdfEU-4uY"
   },
   "source": [
    "### Assign barcodes to well_ids and store as anndata .obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a list for each cell barcode (ubc) component\n",
    "# RT1\n",
    "ubc_1 = []\n",
    "# L2\n",
    "ubc_2 = []\n",
    "#L3\n",
    "ubc_3 = []\n",
    "# The both ligation BCs\n",
    "ubc_23 = []\n",
    "\n",
    "# Loop through each barcode extracting the subsequence\n",
    "for barcode in adata.obs.index.values:\n",
    "  ubc_1.append(barcode[-8:])\n",
    "  ubc_2.append(barcode[8:16])\n",
    "  ubc_3.append(barcode[:8])\n",
    "  ubc_23.append(barcode[:16])\n",
    "  \n",
    "  \n",
    "\n",
    "# Add barcode subsequence to adata .obs\n",
    "adata.obs[\"barcode_1\"] = ubc_1\n",
    "adata.obs[\"barcode_2\"] = ubc_2\n",
    "adata.obs[\"barcode_3\"] = ubc_3\n",
    "adata.obs[\"barcode_2_3\"] = ubc_23\n",
    "\n",
    "# View adata\n",
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read RT BC mapping dataframe contains sample ID numbers\n",
    "# 1-48 are PolyA, 49-96 are rHex\n",
    "mapping_table = pd.read_csv(\"barcode_layouts/barcodes_v2_id_map.csv\")\n",
    "mapping_table.columns = [\"ID\", \"barcode_1\", \"sample_id\"]\n",
    "\n",
    "mapping_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign RT barcodes sample_id and well index\n",
    "indices = []\n",
    "sample_id = []\n",
    "\n",
    "# Loop through the RT barcodes\n",
    "for barcode_1 in adata.obs[\"barcode_1\"]:\n",
    "\n",
    "  # if barcode_1 in mapping dataframe \n",
    "  if barcode_1 in mapping_table[\"barcode_1\"].values:\n",
    "    index_position = mapping_table[\"barcode_1\"] == barcode_1\n",
    "    indices.append(mapping_table[index_position][\"ID\"].values[0])\n",
    "    sample_id.append(mapping_table[index_position][\"sample_id\"].values[0])\n",
    "\n",
    "    # else if barcode_1 is invalid provide warning\n",
    "  else:\n",
    "    indices.append(-1)\n",
    "    sample_id.append(\"invalid\")\n",
    "    print(\"WLIST ERROR, INVALID INDICES PRESENT!!\")\n",
    "\n",
    "# Annotate adata with corresponding well and sample_id data\n",
    "adata.obs[\"index_1\"] = indices\n",
    "adata.obs[\"sample_id\"] = sample_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read mapping daatframe, for Ligation barcodes 2 and 3\n",
    "mapping_table_l23 = pd.read_csv(\"barcode_layouts/barcodes_v1.csv\")\n",
    "mapping_table_l23.columns = [\"ID\", \"barcode\", \"sample_id\"]\n",
    "\n",
    "mapping_table_l23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assing index for L2 barcode\n",
    "indices = []\n",
    "\n",
    "# Loop through the LS barcodes\n",
    "for barcode_2 in adata.obs[\"barcode_2\"]:\n",
    "\n",
    "  # Assign if valid\n",
    "  if barcode_2 in mapping_table_l23[\"barcode\"].values:\n",
    "    index_position = mapping_table_l23[\"barcode\"] == barcode_2\n",
    "    indices.append(mapping_table_l23[index_position][\"ID\"].values[0])\n",
    "\n",
    "    # else if barcode_2 is invalid provide warning\n",
    "  else:\n",
    "    indices.append(-1)\n",
    "    print(\"WLIST ERROR, INVALID INDICES PRESENT!!\")\n",
    "\n",
    "# Annotate adata with corresponding indices\n",
    "adata.obs[\"index_2\"] = indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat process for L3 barcodes\n",
    "indices = []\n",
    "for barcode_3 in adata.obs[\"barcode_3\"]:\n",
    "\n",
    "  if barcode_3 in mapping_table_l23[\"barcode\"].values:\n",
    "    index_position = mapping_table_l23[\"barcode\"] == barcode_3\n",
    "    indices.append(mapping_table_l23[index_position][\"ID\"].values[0])\n",
    "  else:\n",
    "    indices.append(-1)\n",
    "    print(\"WLIST ERROR, INVALID INDICES PRESENT!!\")\n",
    "\n",
    "adata.obs[\"index_3\"] = indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write out indexing well counts to files\n",
    "# unmerged index data for further analysis\n",
    "rt_index_counts = adata.obs['index_1'].value_counts()\n",
    "rt_index_counts.to_csv(\"./pre_processing_figures/data/rt_index_counts.csv\")\n",
    "\n",
    "lig_bc2 = adata.obs['index_2'].value_counts()\n",
    "lig_bc2.to_csv(\"./pre_processing_figures/data/lig_bc2_index_counts.csv\")\n",
    "\n",
    "lig_bc3 = adata.obs['index_3'].value_counts()\n",
    "lig_bc2.to_csv(\"./pre_processing_figures/data/lig_bc_3_index_counts.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check abundance of sample_ID cell barcodes\n",
    "adata.obs['sample_id'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge PolyA and rHex barcodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JSLAC2lF_B1N"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Get unique barcodes and their counts. barcodes_and_counts store both the sequence and the count for each unique barcode.\n",
    "barcodes_and_counts = np.unique(adata.obs[\"barcode_2_3\"].values, return_counts = True)\n",
    "\n",
    "# Store barcodes sequences with 2 counts in adata\n",
    "two_counts_barcodes_2_3 = barcodes_and_counts[0][barcodes_and_counts[1] == 2]\n",
    "\n",
    "# Initialize list to store pairs of barcodes with ID difference different to 48\n",
    "unmatched_barcodes = []\n",
    "\n",
    "# Iterate through barcodes with 2 counts\n",
    "for barcode in two_counts_barcodes_2_3:\n",
    "  # Select rows from adata that have the corresponding barcode_2_3. Calculate index difference\n",
    "  selection = adata.obs[adata.obs[\"barcode_2_3\"].values == barcode]\n",
    "  difference = selection[\"index_1\"][0] - selection[\"index_1\"][1]\n",
    "\n",
    "  # We want to remove the barcode with the higher index. Check ID difference and input each barcode to the combine_distinct_barcode function in the right order.\n",
    "  if difference == -48:\n",
    "    adata = merge_rt_barcodes(adata, selection.index[0], selection.index[1])\n",
    "  elif difference == 48:\n",
    "    adata = merge_rt_barcodes(adata, selection.index[1], selection.index[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S0cDhUIj-Q5X"
   },
   "outputs": [],
   "source": [
    "# Store barcodes_2_3 with multiple counts\n",
    "multiple_counts_barcodes_2_3 = barcodes_and_counts[0][barcodes_and_counts[1] > 2]\n",
    "\n",
    "# Loop through the multimatch barcodes\n",
    "for barcode in multiple_counts_barcodes_2_3:\n",
    "  index = adata.obs[\"barcode_2_3\"] == barcode\n",
    "  \n",
    "  # Compare this barcode to all other barcodes\n",
    "  matched = pairwise_rt_comparison(adata.obs[index][\"index_1\"].values)\n",
    "\n",
    "  # Cerate Matching list\n",
    "  matching_barcodes = []\n",
    "  \n",
    "  # Loop through the RT index pairs barcodes\n",
    "  for pair in matched:\n",
    "\n",
    "    # Add index sequences of paired cell barcodes\n",
    "    matching_barcodes.append(adata.obs[index].index.values[pair])\n",
    "\n",
    "  # Combine barcodes\n",
    "  for matching_barcode in matching_barcodes:\n",
    "    adata = merge_rt_barcodes(adata, matching_barcode[0], matching_barcode[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_index_counts = adata.obs['index_1'].value_counts()\n",
    "rt_index_counts.to_csv(\"split_adt/rt_index_counts_merged.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.calculate_qc_metrics(adata, percent_top=None, log1p=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the adata\n",
    "adata.write('ex0015_adt_80_merged_scanpy.h5ad')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "split-seq_adt.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.10.5 ('scanpy_v1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "3a89b950eb47d00185ca4cabfdcf398a7318f3a27f9b73dc976580ca743d59d8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
